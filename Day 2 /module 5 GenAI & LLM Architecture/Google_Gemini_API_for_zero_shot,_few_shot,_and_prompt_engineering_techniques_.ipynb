{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Google Gemini API for zero-shot, few-shot, and prompt engineering\n",
        "\n",
        "Zero-shot prompting\n",
        "\n",
        "Few-shot prompting\n",
        "\n",
        "Instruction-style prompting\n",
        "\n",
        "Chain-of-thought prompting\n",
        "\n",
        "Role-based prompting"
      ],
      "metadata": {
        "id": "s8YDcHlySRPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 1. Prerequisites\n"
      ],
      "metadata": {
        "id": "JSWsj4UNSbGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q502uxBaSNCC",
        "outputId": "13dc3120-57f6-4b26-9159-f1ccc4038b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "pip install google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 2. Setup Gemini API"
      ],
      "metadata": {
        "id": "Fbmz8R1dSgo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# üîë Set your API key (replace with your actual key)\n",
        "genai.configure(api_key=\"AIzaSyBh3CGd4XyrFlo0JObJxDcu4fgAVPykp94\")\n"
      ],
      "metadata": {
        "id": "3U-wmM7nSeti"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 3. Initialize Gemini Model"
      ],
      "metadata": {
        "id": "yQbCKMO5S1Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Gemini model (text-only model)\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n"
      ],
      "metadata": {
        "id": "WMYoOLC6Syof"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 4. Zero-shot Prompting"
      ],
      "metadata": {
        "id": "Va0Gc27kS4Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üü° Zero-shot: Ask a question without any examples\n",
        "prompt_zero = \"Translate this sentence into hindi: 'Good morning, how are you?'\"\n",
        "\n",
        "response_zero = model.generate_content(prompt_zero)\n",
        "print(\"üü° Zero-shot Output:\\n\", response_zero.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "E2STcyofS2sv",
        "outputId": "0988e15e-4735-4b01-b776-867bb239dd37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üü° Zero-shot Output:\n",
            " Here are a few ways to translate \"Good morning, how are you?\" into Hindi, depending on who you are speaking to (formality and gender):\n",
            "\n",
            "**Most Common & Polite (to anyone, especially adults, strangers, or in professional settings):**\n",
            "\n",
            "*   **‡§∂‡•Å‡§≠ ‡§™‡•ç‡§∞‡§≠‡§æ‡§§, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\n",
            "    *   (Shubh Prabhat, aap kaise hain?)\n",
            "    *   *This uses the respectful \"‡§Ü‡§™\" (aap) and the masculine plural \"‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç\" (kaise hain), which is standard for polite inquiry and can be used for a single male, a group, or generally when the gender isn't specifically known or needs to be respectfully neutral.*\n",
            "\n",
            "**If you know you are speaking to a woman (formally):**\n",
            "\n",
            "*   **‡§∂‡•Å‡§≠ ‡§™‡•ç‡§∞‡§≠‡§æ‡§§, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•Ä ‡§π‡•à‡§Ç?**\n",
            "    *   (Shubh Prabhat, aap kaisi hain?)\n",
            "    *   *Uses \"‡§ï‡•à‡§∏‡•Ä ‡§π‡•à‡§Ç\" (kaisi hain) for a single female.*\n",
            "\n",
            "**If speaking informally to a male friend/peer:**\n",
            "\n",
            "*   **‡§∏‡•Å‡§™‡•ç‡§∞‡§≠‡§æ‡§§, ‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?**\n",
            "    *   (Suprabhat, tum kaise ho?)\n",
            "    *   *Uses the informal \"‡§§‡•Å‡§Æ\" (tum) and \"‡§ï‡•à‡§∏‡•á ‡§π‡•ã\" (kaise ho).*\n",
            "\n",
            "**If speaking informally to a female friend/peer:**\n",
            "\n",
            "*   **‡§∏‡•Å‡§™‡•ç‡§∞‡§≠‡§æ‡§§, ‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•Ä ‡§π‡•ã?**\n",
            "    *   (Suprabhat, tum kaisi ho?)\n",
            "    *   *Uses the informal \"‡§§‡•Å‡§Æ\" (tum) and \"‡§ï‡•à‡§∏‡•Ä ‡§π‡•ã\" (kaisi ho).*\n",
            "\n",
            "**Using \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\" as a common greeting (which can be used any time of day):**\n",
            "\n",
            "*   **‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?**\n",
            "    *   (Namaste, aap kaise hain?)\n",
            "    *   *This is also very common and perfectly acceptable.*\n",
            "\n",
            "The **most universally applicable and polite** translation would be:\n",
            "**‡§∂‡•Å‡§≠ ‡§™‡•ç‡§∞‡§≠‡§æ‡§§, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?** (Shubh Prabhat, aap kaise hain?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 5. Few-shot Prompting"
      ],
      "metadata": {
        "id": "yjsPinvDTRlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üü¢ Few-shot: Give a few examples in the prompt\n",
        "prompt_few = \"\"\"\n",
        "Translate these sentences to hinid:\n",
        "1. Hello, how are you? ‚Üí Bonjour, comment √ßa va ?\n",
        "2. What is your name? ‚Üí Comment tu t'appelles ?\n",
        "3. I love programming. ‚Üí\n",
        "\"\"\"\n",
        "\n",
        "response_few = model.generate_content(prompt_few)\n",
        "print(\"\\nüü¢ Few-shot Output:\\n\", response_few.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "ozX6RAZKS6cu",
        "outputId": "a8571500-4270-46ec-da0c-3dbd882bf32d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üü¢ Few-shot Output:\n",
            " Here are the translations of your sentences into Hindi:\n",
            "\n",
            "1.  **Hello, how are you?** ‚Üí ‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç?\n",
            "    *   *(Namaste, aap kaise hain?)*\n",
            "\n",
            "2.  **What is your name?** ‚Üí ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?\n",
            "    *   *(Aapka naam kya hai?)*\n",
            "\n",
            "3.  **I love programming.** ‚Üí ‡§Æ‡•Å‡§ù‡•á ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ‡§ø‡§Ç‡§ó ‡§ï‡§∞‡§®‡§æ ‡§¨‡§π‡•Å‡§§ ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à‡•§\n",
            "    *   *(Mujhe programming karna bahut pasand hai.)*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 6. Instruction-style Prompting"
      ],
      "metadata": {
        "id": "HOaal459TV1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üî∑ Instruction-style: Direct command\n",
        "prompt_instruction = \"Summarize the following: 'The Great Wall of China was built to protect Chinese states from invasions. It spans over 13,000 miles.'\"\n",
        "\n",
        "response_instruction = model.generate_content(prompt_instruction)\n",
        "print(\"\\nüî∑ Instruction-style Output:\\n\", response_instruction.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "2reZF53FTT3G",
        "outputId": "2dfbfa79-148b-4d1e-c370-bfc6e973fce3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî∑ Instruction-style Output:\n",
            " The Great Wall of China was built to protect Chinese states from invasions and spans over 13,000 miles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 7. Chain-of-Thought Prompting"
      ],
      "metadata": {
        "id": "q92JwVAhTeV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üî∂ Chain-of-Thought: Ask to reason step-by-step\n",
        "prompt_cot = \"Q: A train travels at 60 km/h. How far will it go in 3 hours?\\nA: Let's think step-by-step.\"\n",
        "\n",
        "response_cot = model.generate_content(prompt_cot)\n",
        "print(\"\\nüî∂ Chain-of-Thought Output:\\n\", response_cot.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "HktDC9saTcV-",
        "outputId": "1eb2d26b-53b4-4aea-cecd-e90e36e46bb2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî∂ Chain-of-Thought Output:\n",
            " Okay, let's break it down:\n",
            "\n",
            "**1. What information do we have?**\n",
            "*   **Speed** of the train = 60 kilometers per hour (km/h)\n",
            "*   **Time** the train travels = 3 hours\n",
            "\n",
            "**2. What do we want to find?**\n",
            "*   The **distance** the train will travel.\n",
            "\n",
            "**3. What formula should we use?**\n",
            "The relationship between distance, speed, and time is:\n",
            "Distance = Speed √ó Time\n",
            "\n",
            "**4. Let's plug in the numbers:**\n",
            "Distance = 60 km/h √ó 3 hours\n",
            "\n",
            "**5. Calculate the result:**\n",
            "Distance = 180 km\n",
            "\n",
            "**Answer:** The train will go **180 kilometers** in 3 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ 8. Role-based Prompting"
      ],
      "metadata": {
        "id": "XwbjiMvMTkee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üü£ Role-based: Ask model to take a specific persona\n",
        "prompt_role = \"You are an experienced data scientist. Explain overfitting in simple terms.\"\n",
        "\n",
        "response_role = model.generate_content(prompt_role)\n",
        "print(\"\\nüü£ Role-based Output:\\n\", response_role.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "57ojBvNAThKe",
        "outputId": "cfea30ee-f6e9-4cbb-91c4-b5b71eaf46f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üü£ Role-based Output:\n",
            " Alright, let's break down overfitting in simple terms, the way I'd explain it to a colleague who's new to the field, or even a non-technical stakeholder who needs to grasp the concept.\n",
            "\n",
            "---\n",
            "\n",
            "### Overfitting: Memorizing vs. Understanding\n",
            "\n",
            "Imagine you're trying to teach a student to identify different types of dogs.\n",
            "\n",
            "**1. The Goal:** We want the student to be able to look at *any* dog, even one they've never seen before, and correctly say, \"That's a dog.\"\n",
            "\n",
            "**2. The Training Data:** You show the student 100 pictures of dogs. Let's say these pictures have specific backgrounds (a park, a beach, someone's living room), specific toys, and maybe some of the dogs are wearing little sweaters.\n",
            "\n",
            "**3. What Overfitting Looks Like:**\n",
            "\n",
            "A student who **overfits** doesn't learn the *general characteristics* of \"dog\" (four legs, furry, barks, certain facial features). Instead, they try to **memorize every single detail** from the 100 specific pictures you showed them.\n",
            "\n",
            "*   They might learn: \"A dog *must* be on a beach, or have a red ball, or wear a striped sweater, because that's what I saw in the pictures!\"\n",
            "*   They're paying too much attention to the *noise* or the *irrelevant specific details* in the training examples, rather than the true underlying patterns.\n",
            "\n",
            "**4. The Problem (The \"Test\"):**\n",
            "\n",
            "Now, you show this student a *new* picture ‚Äì a dog they've never seen before. This dog is in a forest, doesn't have a red ball, and isn't wearing a sweater.\n",
            "\n",
            "The overfit student looks at it and says, **\"That's not a dog!\"**\n",
            "\n",
            "Why? Because it doesn't match the *exact specific patterns* they memorized from the training set. They failed to generalize.\n",
            "\n",
            "**In Machine Learning Terms:**\n",
            "\n",
            "*   **Your \"Student\" is our Machine Learning Model.**\n",
            "*   **The \"100 Pictures of Dogs\" is our Training Data.**\n",
            "*   **\"Memorizing every specific detail\" means our model has become too complex and has learned not just the actual patterns in the data, but also the random fluctuations, errors, and noise unique to *that specific training set*.** It's like fitting a wiggly line perfectly through every single data point, even the outliers.\n",
            "*   **The \"New Picture of a Dog\" is our Unseen/New Data (validation or test set).**\n",
            "*   **\"That's not a dog!\" means our model performs very poorly on new, real-world data, even though it performed *perfectly* on the data it was trained on.**\n",
            "\n",
            "---\n",
            "\n",
            "### Why is it a problem?\n",
            "\n",
            "A model that overfits is **useless** in the real world. Its purpose is to make predictions or classifications on *new* data. If it can't do that because it's too fixated on past specific examples, it fails at its core job. It's like having a student who aces all the practice questions but bombs the actual exam.\n",
            "\n",
            "### How do we spot it?\n",
            "\n",
            "The classic sign of overfitting is when your model shows **excellent performance on your training data, but significantly worse performance on new, unseen data.**\n",
            "\n",
            "### How do we fix or prevent it (briefly)?\n",
            "\n",
            "*   **More Data:** The more diverse examples a student sees, the less likely they are to latch onto irrelevant specifics.\n",
            "*   **Simpler Models:** Don't use a super complex model when a simpler one will do. Sometimes a \"less intelligent\" student is better at focusing on the main concepts.\n",
            "*   **Regularization:** Techniques that \"punish\" the model for being too complex or for relying too heavily on any single feature.\n",
            "*   **Cross-Validation:** Systematically testing your model on different subsets of your data to ensure it generalizes well.\n",
            "\n",
            "---\n",
            "\n",
            "So, in essence, overfitting is when your model learns the training data *too well*, including its noise and idiosyncrasies, to the point where it can't generalize to new, unseen data. It's the difference between true understanding and rote memorization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üßæ Summary Table\n",
        "\n",
        "| Prompt Type       | Description                        |\n",
        "| ----------------- | ---------------------------------- |\n",
        "| Zero-shot         | No examples, direct question       |\n",
        "| Few-shot          | Few examples to guide model        |\n",
        "| Instruction-style | Straight command (e.g., summarize) |\n",
        "| Chain-of-thought  | Ask model to reason step-by-step   |\n",
        "| Role-based        | Assign the model a role/persona    |\n"
      ],
      "metadata": {
        "id": "IM2ikNmlTowN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HGF3a57xTmse"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}