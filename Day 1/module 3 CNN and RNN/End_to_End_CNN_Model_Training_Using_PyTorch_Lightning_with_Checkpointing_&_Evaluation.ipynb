{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "777762246219413c92f135330c9a8d0b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fde9ca8af8ed4b60947bf5fed50d1937",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 4/4  \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 25/25 \u001b[2m0:00:02 • 0:00:00\u001b[0m \u001b[2;4m10.19it/s\u001b[0m \u001b[3mv_num: 1.000 val_loss: 2.307       \u001b[0m\n                                                                                \u001b[3mval_acc: 0.130 train_loss: 2.255   \u001b[0m\n                                                                                \u001b[3mtrain_acc: 0.215                   \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4/4  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 25/25 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:02 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">10.19it/s</span> <span style=\"font-style: italic\">v_num: 1.000 val_loss: 2.307       </span>\n                                                                                <span style=\"font-style: italic\">val_acc: 0.130 train_loss: 2.255   </span>\n                                                                                <span style=\"font-style: italic\">train_acc: 0.215                   </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "fde9ca8af8ed4b60947bf5fed50d1937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Objective of This Practical\n",
        "\n",
        "To build a complete end-to-end CNN training pipeline using PyTorch Lightning with a clean, modular, and industry-style workflow.\n",
        "\n",
        "To demonstrate training, validation, accuracy tracking, checkpoint saving, and model loading in a structured ML workflow.\n",
        "\n",
        "# What learner Will Learn\n",
        "\n",
        "1.How to prepare image datasets using torchvision.transforms and FakeData.\n",
        "\n",
        "2.How to create train/validation splits and DataLoaders.\n",
        "\n",
        "3.How to build a simple Convolutional Neural Network (CNN) in PyTorch.\n",
        "\n",
        "4.How to wrap a PyTorch model inside a LightningModule for cleaner training.\n",
        "\n",
        "5.How PyTorch Lightning handles:\n",
        "\n",
        "6.Training loops\n",
        "\n",
        "7.Validation loops\n",
        "\n",
        "8.Logging metrics (loss & accuracy)\n",
        "\n",
        "9.Optimizer setup\n",
        "\n",
        "10.How to use ModelCheckpoint to save the best model.\n",
        "\n",
        "11.How to reload the saved checkpoint and perform inference.\n",
        "\n",
        "12.How to ensure reproducibility with proper seeding.\n",
        "\n",
        "13.How to run everything efficiently on CPU/GPU automatically."
      ],
      "metadata": {
        "id": "mJc3FxEqZFcF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrojxUoEWZAn",
        "outputId": "fca6108f-08af-4247-d80e-9184114fd533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run once in notebook)\n",
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch core library for tensors and computations\n",
        "import torch\n",
        "\n",
        "# Import neural network module (layers like Conv2d, Linear, etc.)\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import optimization algorithms such as Adam, SGD, etc.\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import DataLoader for batching & shuffling datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Import image transforms and standard datasets like MNIST/CIFAR\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Import Python's random module for reproducibility\n",
        "import random\n",
        "\n",
        "# Import NumPy for array operations and seeding\n",
        "import numpy as np\n",
        "\n",
        "# Detect GPU if available, else fallback to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Print which device is being used for computation\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd2D6UjVWa0z",
        "outputId": "c06ea5cf-3bbe-4130-f671-84cdce687583"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a fixed seed value for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# Apply seed to PyTorch CPU operations\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Apply seed to NumPy operations\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Apply seed to Python's built-in random module\n",
        "random.seed(seed)\n",
        "\n",
        "# If running on GPU, set CUDA-specific seeds as well\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(seed)\n"
      ],
      "metadata": {
        "id": "LWPYWFXlWb_g"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fake image dataset (CIFAR-like: 3×32×32) for quick demo/testing\n",
        "# FakeData generates random images + labels (useful to test model pipeline)\n",
        "\n",
        "# Define transforms to apply on each image\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                                 # Convert image to tensor (C,H,W) with values in [0,1]\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize each channel to roughly [-1, 1]\n",
        "])\n",
        "\n",
        "# Create a random dataset with 1000 samples, 3 channels, 32×32 resolution and 10 classes\n",
        "dataset = datasets.FakeData(\n",
        "    size=1000,\n",
        "    image_size=(3, 32, 32),\n",
        "    num_classes=10,\n",
        "    transform=transform,     # Apply transforms on each image\n",
        "    random_offset=0          # Makes dataset deterministic\n",
        ")\n",
        "\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoader for batching and shuffling the dataset\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "UAhuJvftWdkH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple CNN architecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # --- Convolution Block 1 ---\n",
        "        # First conv layer: input channels=3, output channels=16, kernel=3x3, padding=1 (keeps size same)\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "        # Activation function\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # Max pooling: reduces spatial size from 32x32 → 16x16\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # --- Convolution Block 2 ---\n",
        "        # Second conv: 16 → 32 channels\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        # Activation function\n",
        "        self.relu2 = nn.ReLU()\n",
        "        # Pooling: reduces 16x16 → 8x8\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # --- Fully Connected Layers ---\n",
        "        # FC layer: flatten 32×8×8 → 128 features\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
        "        # Activation function\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # Output layer for number of classes\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape = (batch_size, 3, 32, 32)\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))   # Apply conv1 → relu1 → pool1\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))   # Apply conv2 → relu2 → pool2\n",
        "\n",
        "        # Flatten tensor for FC layers\n",
        "        x = x.view(x.size(0), -1)                   # Shape becomes (batch, 32*8*8)\n",
        "\n",
        "        # Apply first fully connected layer + activation\n",
        "        x = self.relu3(self.fc1(x))\n",
        "\n",
        "        # Output layer → raw class logits\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create model instance and move to CPU/GPU\n",
        "model = SimpleCNN(num_classes=10).to(device)\n",
        "\n",
        "# Print network architecture summary\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsLqlYP5Wep6",
        "outputId": "15c9515d-aff0-4704-b50c-f6460a2505d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function (CrossEntropyLoss is used for multi-class image classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam optimizer to update CNN weights during training (learning rate = 0.001)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "sdTDA0d1WfyC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of training epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Put model in training mode (enables dropout, batchnorm updates if present)\n",
        "model.train()\n",
        "\n",
        "# Loop over epochs\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Track total loss for the epoch\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Loop through each batch from the DataLoader\n",
        "    for i, (inputs, labels) in enumerate(loader):\n",
        "\n",
        "        # Move image batch to CPU/GPU\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        # Move label batch to CPU/GPU\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # --- Forward pass ---\n",
        "        outputs = model(inputs)                # Get model predictions (logits)\n",
        "        loss = criterion(outputs, labels)      # Calculate loss for this batch\n",
        "\n",
        "        # --- Backward + Optimize ---\n",
        "        optimizer.zero_grad()                  # Clear previous gradients\n",
        "        loss.backward()                        # Backpropagate to compute gradients\n",
        "        optimizer.step()                       # Update model weights\n",
        "\n",
        "        # Add loss to running total\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Compute average loss over all batches in this epoch\n",
        "    avg_loss = running_loss / len(loader)\n",
        "\n",
        "    # Print epoch result\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Avg Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t0clw5hWg_S",
        "outputId": "b98c1eb1-2966-481f-8b7d-96f3c32c1ec6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] - Avg Loss: 2.3108\n",
            "Epoch [2/5] - Avg Loss: 2.2977\n",
            "Epoch [3/5] - Avg Loss: 2.2919\n",
            "Epoch [4/5] - Avg Loss: 2.2827\n",
            "Epoch [5/5] - Avg Loss: 2.2666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick evaluation on a few samples (not a real test split, just demo)\n",
        "model.eval()   # Set model to evaluation mode (disables dropout/batchnorm updates)\n",
        "\n",
        "# Disable gradient calculation (faster + saves memory)\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Get one batch of data from the loader\n",
        "    sample_inputs, sample_labels = next(iter(loader))\n",
        "\n",
        "    # Move inputs to CPU/GPU\n",
        "    sample_inputs = sample_inputs.to(device)\n",
        "\n",
        "    # Move labels to CPU/GPU\n",
        "    sample_labels = sample_labels.to(device)\n",
        "\n",
        "    # Forward pass to get predictions\n",
        "    logits = model(sample_inputs)\n",
        "\n",
        "    # Convert logits to predicted class indices\n",
        "    preds = logits.argmax(dim=1)\n",
        "\n",
        "    # Print first 10 true vs predicted labels\n",
        "    for idx in range(10):\n",
        "        print(f\"True: {int(sample_labels[idx].item())}  Pred: {int(preds[idx].item())}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlefoLPnWh5S",
        "outputId": "fa53e761-6479-47c2-c343-4c08229b2062"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: 5  Pred: 3\n",
            "True: 6  Pred: 3\n",
            "True: 6  Pred: 3\n",
            "True: 2  Pred: 8\n",
            "True: 6  Pred: 3\n",
            "True: 6  Pred: 3\n",
            "True: 1  Pred: 3\n",
            "True: 8  Pred: 3\n",
            "True: 7  Pred: 3\n",
            "True: 8  Pred: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#single, ready-to-run PyTorch Lightning notebook cell that includes:\n",
        "\n",
        "> train / val split (validation split),\n",
        "\n",
        "> batch & epoch accuracy logging,\n",
        "\n",
        "> saving best checkpoint (by val_loss),\n",
        "\n",
        "> loading that checkpoint for inference,\n",
        "\n",
        "> saving state_dict separately."
      ],
      "metadata": {
        "id": "nCR6Ckx5W991"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (uncomment if needed; quiet to reduce output)\n",
        "!pip install torch torchvision pytorch_lightning --quiet\n",
        "\n",
        "# OS utilities (file paths, dirs)\n",
        "import os\n",
        "# Python random utilities for reproducibility\n",
        "import random\n",
        "# NumPy for numeric ops and seeding\n",
        "import numpy as np\n",
        "# Core PyTorch library\n",
        "import torch\n",
        "# Neural network modules (layers, losses, etc.)\n",
        "import torch.nn as nn\n",
        "# PyTorch optimizers (Adam, SGD, ...)\n",
        "import torch.optim as optim\n",
        "# DataLoader and random_split for batching and splitting datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "# Image transforms and toy datasets from torchvision\n",
        "from torchvision import transforms, datasets\n",
        "# PyTorch Lightning high-level training framework\n",
        "import pytorch_lightning as pl\n",
        "# Lightning callback to save model checkpoints\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# ----------------------------\n",
        "# Reproducibility & device\n",
        "# ----------------------------\n",
        "# Fixed random seed value for reproducibility\n",
        "seed = 42\n",
        "# Seed Python's random module\n",
        "random.seed(seed)\n",
        "# Seed NumPy RNG\n",
        "np.random.seed(seed)\n",
        "# Seed PyTorch CPU RNG\n",
        "torch.manual_seed(seed)\n",
        "# If CUDA available, seed all CUDA devices for reproducibility\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Choose device: GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Print which device will be used for compute\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ----------------------------\n",
        "# Dataset & transforms\n",
        "# ----------------------------\n",
        "# Compose transforms: convert PIL to tensor and normalize channels\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                              # PIL->Tensor with shape (C,H,W) and values in [0,1]\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))  # Normalize each channel to roughly [-1,1]\n",
        "])\n",
        "\n",
        "# Create a FakeData dataset (CIFAR-like, 3x32x32, deterministic with random_offset=0)\n",
        "full_dataset = datasets.FakeData(\n",
        "    size=1000,                 # total samples\n",
        "    image_size=(3,32,32),      # image shape (C,H,W)\n",
        "    num_classes=10,            # number of target classes\n",
        "    transform=transform,       # transforms to apply to each sample\n",
        "    random_offset=0            # deterministic offset for repeatability\n",
        ")\n",
        "\n",
        "# Compute train/validation split sizes (80% train, 20% val)\n",
        "train_len = int(0.8 * len(full_dataset))\n",
        "val_len = len(full_dataset) - train_len\n",
        "\n",
        "# Split dataset into train and validation sets using fixed generator seed\n",
        "train_dataset, val_dataset = random_split(\n",
        "    full_dataset,\n",
        "    [train_len, val_len],\n",
        "    generator=torch.Generator().manual_seed(seed)  # deterministic split\n",
        ")\n",
        "\n",
        "# Batch size for training/validation\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoader for training: shuffles each epoch\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "# DataLoader for validation: no shuffle to keep deterministic ordering\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "# ----------------------------\n",
        "# Simple CNN definition\n",
        "# ----------------------------\n",
        "class SimpleCNN(nn.Module):\n",
        "    # Initialize with number of classes (default 10)\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # First convolutional layer: 3 input channels -> 16 output channels\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  # keeps spatial size the same\n",
        "        # ReLU activation after conv1\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # MaxPool reduces spatial dims by factor 2 (32x32 -> 16x16)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        # Second convolutional layer: 16 -> 32 channels\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # keeps spatial size before pooling\n",
        "        # ReLU activation after conv2\n",
        "        self.relu2 = nn.ReLU()\n",
        "        # Second pooling (16x16 -> 8x8)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        # Fully connected layer: flatten 32*8*8 features -> 128\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
        "        # ReLU activation for FC\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # Final FC to get logits for each class\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    # Forward pass: defines how input tensor moves through the network\n",
        "    def forward(self, x):\n",
        "        # conv1 -> relu -> pool1 sequence\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        # conv2 -> relu -> pool2 sequence\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        # Flatten tensor: (batch, channels, H, W) -> (batch, channels*H*W)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # Fully connected layer + activation\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        # Output logits (no softmax; CrossEntropy expects raw logits)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ----------------------------\n",
        "# Lightning Module with accuracy calculation\n",
        "# ----------------------------\n",
        "class LitCNN(pl.LightningModule):\n",
        "    # Accept a PyTorch model and learning rate\n",
        "    def __init__(self, model: nn.Module, lr: float = 1e-3):\n",
        "        super().__init__()\n",
        "        # Store the underlying model (SimpleCNN)\n",
        "        self.model = model\n",
        "        # Learning rate for optimizer\n",
        "        self.lr = lr\n",
        "        # Loss function for multi-class classification\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Save hyperparameters (lr is saved; model is ignored to avoid pickling)\n",
        "        self.save_hyperparameters(ignore=['model'])\n",
        "\n",
        "    # Forward pass delegates to the underlying model\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    # Training step executed for each batch during training\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Unpack inputs and targets from the batch\n",
        "        inputs, targets = batch\n",
        "        # Forward pass: get logits\n",
        "        logits = self(inputs)\n",
        "        # Compute cross-entropy loss\n",
        "        loss = self.criterion(logits, targets)\n",
        "\n",
        "        # Compute batch predictions (class indices)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        # Count correct predictions in the batch\n",
        "        batch_correct = (preds == targets).sum().float()\n",
        "        # Batch accuracy as fraction\n",
        "        batch_acc = batch_correct / targets.size(0)\n",
        "\n",
        "        # Log train loss and accuracy averaged across epoch (on_epoch=True)\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_acc', batch_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        # Return loss for optimizer step\n",
        "        return loss\n",
        "\n",
        "    # Validation step executed for each batch during validation\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # Unpack batch\n",
        "        inputs, targets = batch\n",
        "        # Forward pass\n",
        "        logits = self(inputs)\n",
        "        # Compute validation loss\n",
        "        loss = self.criterion(logits, targets)\n",
        "\n",
        "        # Compute predictions and batch accuracy\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        batch_correct = (preds == targets).sum().float()\n",
        "        batch_acc = batch_correct / targets.size(0)\n",
        "\n",
        "        # Log validation loss and accuracy (averaged across epoch)\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_acc', batch_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        # Return metrics for potential further aggregation\n",
        "        return {\"val_loss\": loss, \"val_acc\": batch_acc}\n",
        "\n",
        "    # Configure optimizer used for training\n",
        "    def configure_optimizers(self):\n",
        "        # Use Adam optimizer over LightningModule parameters with chosen lr\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "# ----------------------------\n",
        "# Instantiate model, LightningModule, and checkpoint callback\n",
        "# ----------------------------\n",
        "# Create SimpleCNN instance with 10 classes\n",
        "cnn = SimpleCNN(num_classes=10)\n",
        "# Wrap the PyTorch model into the LightningModule with learning rate 1e-3\n",
        "lit_model = LitCNN(cnn, lr=1e-3)\n",
        "\n",
        "# Directory to store checkpoints\n",
        "checkpoint_dir = \"checkpoints\"\n",
        "# Create directory if it does not exist\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# ModelCheckpoint callback: save the best model based on minimum val_loss\n",
        "ckpt_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',                                 # metric to monitor\n",
        "    dirpath=checkpoint_dir,                             # where to save\n",
        "    filename='best-checkpoint-{epoch:02d}-{val_loss:.4f}', # filename template\n",
        "    save_top_k=1,                                       # keep only best checkpoint\n",
        "    mode='min'                                          # minimize monitored metric\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# Trainer: run training\n",
        "# ----------------------------\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=5,                      # number of epochs to train\n",
        "    callbacks=[ckpt_callback],         # checkpoint callback to save best model\n",
        "    log_every_n_steps=20,              # log frequency in steps\n",
        "    accelerator='auto',                # automatically choose CPU/GPU/TPU\n",
        "    devices=1 if torch.cuda.is_available() else 1, # run on 1 device (CPU or GPU)\n",
        "    deterministic=True                 # try to make runs deterministic\n",
        ")\n",
        "\n",
        "# Start training using train and validation dataloaders\n",
        "trainer.fit(lit_model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
        "\n",
        "# ----------------------------\n",
        "# After training: path to best checkpoint & demonstration of loading\n",
        "# ----------------------------\n",
        "# Get path to the best saved checkpoint (empty string if none saved)\n",
        "best_ckpt = ckpt_callback.best_model_path\n",
        "# Print path or message if no checkpoint saved\n",
        "print(\"Best checkpoint path:\", best_ckpt if best_ckpt else \"No checkpoint saved\")\n",
        "\n",
        "# If a best checkpoint exists, load it and run example inference\n",
        "if best_ckpt:\n",
        "    # Load LightningModule from checkpoint (provide a fresh model object if required)\n",
        "    loaded = LitCNN.load_from_checkpoint(best_ckpt, model=SimpleCNN(num_classes=10))\n",
        "    # Move loaded module to chosen device (GPU/CPU)\n",
        "    loaded.to(device)\n",
        "    # Set module to evaluation mode\n",
        "    loaded.eval()\n",
        "\n",
        "    # Grab one validation batch for demo inference\n",
        "    batch_inputs, batch_labels = next(iter(val_loader))\n",
        "    # Move batch inputs to device\n",
        "    batch_inputs = batch_inputs.to(device)\n",
        "    # Move batch labels to device\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    # Disable gradient computation for inference (faster & memory efficient)\n",
        "    with torch.no_grad():\n",
        "        # Get logits from the loaded model\n",
        "        logits = loaded(batch_inputs)\n",
        "        # Convert logits to predicted class indices\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "    # Print a sample of predictions (first up to 10)\n",
        "    print(\"\\nSample predictions (first 10):\")\n",
        "    for i in range(min(10, len(preds))):\n",
        "        print(f\"True: {int(batch_labels[i].item())}  Pred: {int(preds[i].item())}\")\n",
        "\n",
        "    # Optionally save the state_dict of the underlying PyTorch model\n",
        "    final_state_path = os.path.join(checkpoint_dir, \"final_model_state_dict.pth\")\n",
        "    torch.save(loaded.model.state_dict(), final_state_path)\n",
        "    # Confirm saved path\n",
        "    print(\"Saved model state_dict to:\", final_state_path)\n",
        "else:\n",
        "    # Inform user that no checkpoint was saved to load\n",
        "    print(\"No checkpoint to load.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Notes:\n",
        "# - Checkpoints saved under the 'checkpoints' directory.\n",
        "# - Lightning logs (train_loss/train_acc/val_loss/val_acc) appear in the progress bar and can be used by loggers.\n",
        "# - To use a real dataset replace FakeData with CIFAR10 or MNIST from torchvision.datasets (will download data).\n",
        "# ----------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603,
          "referenced_widgets": [
            "777762246219413c92f135330c9a8d0b",
            "fde9ca8af8ed4b60947bf5fed50d1937"
          ]
        },
        "id": "Gr8b9UBcW0L1",
        "outputId": "37405f21-cc8f-4d92-d157-6a499a72af9d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:881: Checkpoint directory /content/checkpoints exists and is not empty.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model     │ SimpleCNN        │  268 K │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ criterion │ CrossEntropyLoss │      0 │ train │     0 │\n",
              "└───┴───────────┴──────────────────┴────────┴───────┴───────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model     │ SimpleCNN        │  268 K │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ criterion │ CrossEntropyLoss │      0 │ train │     0 │\n",
              "└───┴───────────┴──────────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 268 K                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 268 K                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 11                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 268 K                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 268 K                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 11                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "777762246219413c92f135330c9a8d0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best checkpoint path: /content/checkpoints/best-checkpoint-epoch=01-val_loss=2.3032-v1.ckpt\n",
            "\n",
            "Sample predictions (first 10):\n",
            "True: 2  Pred: 8\n",
            "True: 5  Pred: 8\n",
            "True: 6  Pred: 8\n",
            "True: 2  Pred: 8\n",
            "True: 0  Pred: 8\n",
            "True: 8  Pred: 8\n",
            "True: 3  Pred: 8\n",
            "True: 7  Pred: 8\n",
            "True: 1  Pred: 8\n",
            "True: 5  Pred: 8\n",
            "Saved model state_dict to: checkpoints/final_model_state_dict.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "muvF4gQSXN3X"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}